# 最优化方法

## 1.基本概念

静态的最优化问题，其表现形式有三种

第一种最优化问题表示形式为

![image-20200323141141765](D:\learn\笔记\最优化笔记.assets\image-20200323141141765.png)

第二种最优化问题表示形式为

![image-20200323141211313](D:\learn\笔记\最优化笔记.assets\image-20200323141211313.png)

第三种最优化问题表示形式为

![image-20200323141249298](D:\learn\笔记\最优化笔记.assets\image-20200323141249298.png)

其中

![image-20200323141302693](D:\learn\笔记\最优化笔记.assets\image-20200323141302693.png)

满足所有约束的点称为**容许点或可行点**．容许点的集合称为容许集或可行域．可用表示

![image-20200323141351661](D:\learn\笔记\最优化笔记.assets\image-20200323141351661.png)

一般地，对于最优化问题的求解，是指在可行域内找一点，使得目标函数在该点取得极小值，即

![image-20200323141638001](D:\learn\笔记\最优化笔记.assets\image-20200323141638001.png)

这样的称为问题的最优点，也称极小点，而相应的目标函数值 称为最优值；　　　

  合起来称为最优解，但习惯上把　本身称为**最优解**．最优点的各分量和最优值必须是有限数



**二维最优化问题的图解法**

![image-20200323141829498](D:\learn\笔记\最优化笔记.assets\image-20200323141829498.png)

约束集合

- 当约束函数为线性时，**等式约束在坐标平面上为一条直线，不等式约束在坐标平面上为一半平面**
- 当约束函数为非线性时，等式约束条件在坐标平面上为一条曲线（如图），不等式约束把坐标平面分成两部分当中的一部分（如图）．



![image-20200323141905782](D:\learn\笔记\最优化笔记.assets\image-20200323141905782.png)



**Example 1**

在坐标平面上画出约束集合

![image-20200323142330782](D:\learn\笔记\最优化笔记.assets\image-20200323142330782.png)

满足的区域为以原点为圆心，半径为1的圆；满足的区域为第一象限的扇形（如图所示）

![image-20200323142424542](D:\learn\笔记\最优化笔记.assets\image-20200323142424542.png)

### 1.1等高线

​      我们知道在三维空间中$t=f(x_{1},x_{2})$表示一张曲面 ${t=c}$．其中 $c$ 为常数）在三维空间中表示平行于 $x_{1},x_{2}$平面的一个平面，这个平面上任何一点的高度都等于常数 （如图）．

![image-20200323144049463](D:\learn\笔记\最优化笔记.assets\image-20200323144049463.png)

在三维空间中曲面$t=f(x_{1},x_{2})$与平面  $t=c$  有一条交线  ．交线在平面上的投影曲线是  $L$，可见曲线上的点到平面的高度都等于常数C，也即曲线上的的函数值都具有相同的值．

- 当常数取不同的值时，重复上面的讨论，在平面上得到一族曲线——等高线.

- 等高线的形状完全由曲面的形状所决定；反之，由等高线的形状也可以推测出曲面的形状．

**Example **

在坐标平面  $f(x_{1},x_{2})=x_{1}^2+x_{2}^2$上画出目标函数的等高线．

![image-20200323144506622](D:\learn\笔记\最优化笔记.assets\image-20200323144506622.png)

**Example 2**

用图解法求解二维最优化问题

![image-20200323145119866](D:\learn\笔记\最优化笔记.assets\image-20200323145119866.png)

如图，目标函数的等高线是以$[-2,-2]^T$为圆心的同心圆，并且这族同心圆的外圈比内圈的目标函数值大．因此，该问题为在约束集中找一点,使其落在半径最小的那个同心圆上。问题的最优解为：$X^{*}=[x_{1},x_{2}]^T=[0.0^T]$



### 1.2 最优化问题的迭代解法

最优化问题的迭代算法是指：从某一选定的初始点出发，根据目标函数、约束函数在该点的某些信息，确定本次迭代的一个搜索方向和适当的步长，从而到达一个新点，用式子表示即为
$$
X_{k+1}=X_{k}+t_{k}P_{k}
$$

- ${X_{k}}$ ：前一次已经取得的迭代点，在开始计算时为迭代初始点$X_{0}$

- $X_{k+1}$:新的k迭代点
- $P_{k}$：第k次迭代计算的步因子
- $t_{k}$:第k次迭代计算的步长因子

如果是求一个约束的极小点，则每一次迭代的新点都应该在约束可行域内，即

![image-20200323153233030](D:\learn\笔记\最优化笔记.assets\image-20200323153233030.png)

下图为迭代过程

![image-20200323153239754](D:\learn\笔记\最优化笔记.assets\image-20200323153239754.png)

### 1.3 计算终止准则

对于无约束优化问题通常采用的迭代终止准则有以下几种：

- 点距准则

  相邻两迭代点之间的距离已达到充分小，即$ ||X_{k+1}-X_{k}||\leq \varepsilon$式中  是一个充分小正数，$\varepsilon$代表计算精度．

- 函数下降量准则

相邻两迭代点的函数值下降量已达到充分小,当$|f(X_{k+1})|\leq1$时，可用函数绝对下降量准则![image-20200323163356880](D:\learn\笔记\最优化笔记.assets\image-20200323163356880.png)

- 梯度准则

目标函数在迭代点的梯度已达到充分小，即![image-20200323163156753](D:\learn\笔记\最优化笔记.assets\image-20200323163156753.png)这一准则对于定义域上的凸函数是完全正确的．若是非凸函数，有可能导致误把驻点作为最优点。对于约束优化问题，不同的优化方法有各自的终止准则．

综上所述，优化算法的基本迭代过程如下：

- 选定初始点$x_{0}$,置$K=0$
- 按照某种规则确定搜索方向$P_{k}$
- 按照某种规则确定$t_{k}$使得$f(X_{k}+t_{k}P_{k})<f(X_{k})$
- 计算 $X_{k+1}=X_{k}+t_{k}P_{k}$
- 判定$X_{k+1}$是否满足终止准则。若满足，则返回$X_{k+1}$和$f(X_{k+1})$ ;否则k=k+1 

优化算法当然还可以从别的角度进行分类，如**确定性算法和不确定性算法**，**局部优化算法和全局优化算法**等．

### 1.4 组合优化问题建模

最优化问题可分为函数优化问题和组合优化问题两大类.

**函数优化**问题，该函数优化的对象是**一定区间内的连续变量**。

**组合优化**的对象是解空间中的离散状态．



## 2.一维搜索法

最优化问题其关键在于如何构造一个搜索方向$P_{K}\epsilon R^{n}$ 和确定一个步长$t_{k} \epsilon R^{1} $ ,使下一个迭代点$X_{k+1}$ 处的目标函数值下降，即$f(X_{k+1}<f(X_{k}))$  当搜索方向$P_{K}$  已经确定的情况下，如何来确定步长$t_{k}$  . 

步长因子的选择有很多种方法：

- 常数
- 一维搜索来确定最优步长

对无约束最优化问题

![image-20200323173228273](D:\learn\笔记\最优化笔记.assets\image-20200323173228273.png)

当已知迭代点 $X_{k} $和下降方向$P_{k}$  时，要确定适当的步长  $t_{k}$ 使 $f(X_{k+1}=f(X_{k}+t_{k}P_{k}))$比$f(X_{k})$ 有所下降，即相当于关于t的函数。$\delta(t)=f(X_{k}+tP_{k})$ 要在区间$[0,+\infty]$上选取$t=t_{k}$使$f(X_{k+1})<f(X_{k})$

由于这种从已知点 $X_{k}$ 出发，沿某一下降的探索方向$P_{k}$ 来确定步长$t_{k}$ 的问题，实质上是单变量函数  $t$关于变量 的一维搜索选取问题，故通常叫做**一维搜索**

按这种方法确定的步长 $t_{k}$又称为**最优步长**,这种方法的优点是:**它使目标函数值在搜索方向上下降得最多**．
$$
Z=ls(X,P) 
$$
表示从点$x_{k}$出发沿着方向$P_{k}$对目标函数做直线搜索所得到的极小值是$X_{k+1}$. ls is Linear search

在目标函数$f(X)$已确定的条件下等价于：

![image-20200323174430593](D:\learn\笔记\最优化笔记.assets\image-20200323174430593.png)

下面进一步解释迭代点$X_{k+1}=X_{k}+t_{k}P_{k}$的空间位置，容易证明，若从$X_{k}$出发，沿$P_{k}$方向进步一维搜索极小点

，则该点$X=X_{k+1}$处的梯度方向
$$
\nabla f(X_{k+1})^TP_{k}=0
$$


事实上，设$\varphi(t)=f(X_{k}+tP_{k})$，对$t$求导有
$$
\varphi^{'}(t)=\nabla f(X_{k}+tP_{k})^TP_{k} ··········(2.1)
$$
令$\varphi^{'}(t)=0$,即$\nabla f(X_{k}+tP_{k})^TP_{k}=0$

所以 $\nabla f(X_{k+1})^TP_{k}=0$

几何意义：

从某一点 $X_{k}$出发沿方向 $X_{k}$对目标函数 $X_{k}$作直线搜索,所得到的极小点为$X_{k}$  式（2.1）指出，梯度 $\nabla f(X_{k+1})$ 必与搜索方向 $P_{k}$正交.又因为  $\nabla f(X_{k+1})$ 与目标函数过点 $X_{k+1}$ 的等值面   $f(X)=f(X_{k+1})$  正交，所以进一步看到，搜索方向$P_{k}$  与这个等值面在点  $X_{k+1}$处相切（如图所示）． 

![image-20200323180540037](D:\learn\笔记\最优化笔记.assets\image-20200323180540037.png)





###  2.1搜索区间及其确定方法

**加步探索法**

### 2.2 对分法

### 2.3 **Newton切线法**

### 2.4 黄金分割法

### 2.5 抛物线插值法

## 3 常见无约束最优化方法

多维无约束最优化问题
$$
min f(X)
$$
其中$f:R^{n}\rightarrow R^{1}$ 这个问题的求解是指在$R^{n}$中找到一个点$X^{*}$,使得对于任意的$X \in R^{n}$都有
$$
f(X^{*}\leq f(X))
$$
成立，则点$X^{*}$就是问题的全局最优点。

但是大多数的最优化方法只能求到局部最优点

无约束优化理论发展较早，比较成熟，方法也很多，新的方法还在陆续出现．把这些方法归纳起来可以分成两大类：一类是**仅用计算函数值所得到的信息来确定搜索方向**，通常称它为**直接搜索法**，简称为直接法，另一类**需要计算函数的一阶或二阶导数值所得到的信息来确定搜索方向**，这一类方法称为**间接法**（解析法）．

直接法不涉及导数、$Hesse$矩阵，适应性强，但**收敛速度较慢**；间接法收敛速度快，但需计算梯度，甚至需要计算$Hesse$矩阵.

  一般的经验是,**在可能求得目标函数导数的情况下还是尽可能使用间接方法；相反,在不可能求得目标函数的导数或根本不存在导数的情况下,当然就应该使用直接法**

### 3.1 最速下降法



### 3.2 共轭梯度下降

本质:目标函数分成许多方向，然后不同方向分别求出极值在综合起来

### 3.3 随机梯度下降法

#### 3.3.1 动量

**Momentum**改进自SGD算法，让每一次的参数更新方向不仅仅取决于当前位置的梯度，还受到上一次参数更新方向的影响：
$$
d_{i}=\beta d_{i-1}+g(\theta_{i-1})
$$
$\theta_{i}=\theta_{i-1}+\alpha d_{i}$其中，$d_{i}$和$d_{i-1}$ 分别是当前和上次更新的方向，$g(\theta)$表示目标函数在$\theta$处的梯度，超参数$\beta$是对上一次更新方向的衰减权重，在所以在$[0-1]$,$\alpha$是学习率。总的来说，总的更新包括上次的更新量和当前的更新量。所以Momentum的想法很简单，就是多更新一部分上一次迭代的更新量，来平滑这一次迭代的梯度。从物理的角度上解释，就像是一个小球滚落的时候会受到自身历史动量的影响，所以才叫动量（Momentum）算法。这样做直接的效果就是使得梯度下降的的时候转弯掉头的幅度不那么大了，于是就能够更加平稳、快速地冲向局部最小点。

#### 3.3.2 Nesterov梯度加速法

然后NAG就对Momentum说：“既然我都知道我这一次一定会走$\alpha \beta d_{i-1}$ 的量，那么我何必还用现在这个位置的梯度呢？我直接先走到$\alpha \beta d_{i-1}$ 之后的地方，然后再根据哪里的梯度再往前进一步，岂不是更方便" 
$$
d_{i}=\beta d_{i-1}+g(\theta_{i-1}-\alpha \beta d_{i-1})
$$
$\theta_{i}=\theta_{i-1}+\alpha d_{i}$

![image-20200324174409241](C:\Users\weiyudang\AppData\Roaming\Typora\typora-user-images\image-20200324174409241.png)

NAG本质上是多考虑了目标函数**二阶导信息**！其实所谓“往前看”的说法，在牛顿法这样的二阶方法中也是经常提到的，比喻起来是说“往前看”，数学本质上则是利用了目标函数的二阶导信息。

#### 3.3.3 Adagrad方法

#### 3.3.4 AdaDelta方法

#### 3.3.5 Adam算法

## 4. reference

- [理解牛顿法](https://zhuanlan.zhihu.com/p/37588590)



